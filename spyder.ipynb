{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import json\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Twitter的URL\n",
    "twitter_url = 'https://twitter.com/'\n",
    "\n",
    "# 从文件加载cookies\n",
    "cookies_path = r'\\twitter_Crawler\\twitter_cookie.json'\n",
    "with open(cookies_path, 'r', encoding='utf-8') as cookies_file:\n",
    "    cookies = json.load(cookies_file)\n",
    "\n",
    "# 访问Twitter\n",
    "driver.get(twitter_url)\n",
    "\n",
    "# 等待页面加载完成\n",
    "time.sleep(5)\n",
    "\n",
    "# 添加cookie到浏览器\n",
    "for cookie in cookies:\n",
    "    driver.add_cookie(cookie)\n",
    "\n",
    "# 再次访问Twitter，这次将会使用加载的cookies\n",
    "driver.get(twitter_url)\n",
    "\n",
    "# Twitter搜索URL\n",
    "twitter_search_url = '替换搜索结果连接，如要爬取\"Python\"相关的推文，在Twitter搜索\"Python\"，然后复制URL到这里'\n",
    "\n",
    "# 导航到Twitter搜索页面\n",
    "driver.get(twitter_search_url)\n",
    "time.sleep(5)  # 给页面时间加载\n",
    "\n",
    "# 用于存储抓取到的数据\n",
    "tweets_data = []\n",
    "\n",
    "# 设置要滚动的次数\n",
    "scrolls = 3\n",
    "for i in range(scrolls):\n",
    "    # 找到所有的推文元素\n",
    "    tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]')\n",
    "    for tweet in tweets:\n",
    "        # 提取用户名\n",
    "        user_name = tweet.find_element(By.XPATH, './/span').text\n",
    "\n",
    "        # 提取文本内容\n",
    "        tweet_text = tweet.find_element(By.XPATH, './/div[2]/div[2]/div[2]/div[1]').text\n",
    "\n",
    "        # 提取图片链接（如果有的话）\n",
    "        image_url = None\n",
    "        try:\n",
    "            image_element = tweet.find_element(By.XPATH, './/img[@alt=\"图像\"]')\n",
    "            image_url = image_element.get_attribute('src')\n",
    "        except Exception as e:\n",
    "            pass  # 如果没有找到图片，则跳过\n",
    "\n",
    "        # 存储数据\n",
    "        tweets_data.append({\n",
    "            'user_name': user_name,\n",
    "            'text': tweet_text,\n",
    "            'image_url': image_url,\n",
    "        })\n",
    "\n",
    "    # 滚动到页面底部\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(2)  # 等待页面加载新的推文\n",
    "\n",
    "# 将数据保存为JSON文件\n",
    "with open('tweets_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(tweets_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 完成后关闭浏览器\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
